{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53a78804-08f4-4ef3-a2ce-c062ba0d7a74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Stream Customers Data From Cloud Files to Delta Lake\n",
    "1. Read files from cloud storage using DataStreamReader API\n",
    "2. Transform the dataframe to add the following columns\n",
    "    - file path: Cloud file path\n",
    "    - ingestion date: Current Timestamp\n",
    "3. Write the transformed data stream to Delta Lake Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3eb8be86-e381-4258-a6f2-b231d3a10c49",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "1. Read files from cloud storage using DataStreamReader API"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "customers_schema = StructType(\n",
    "    fields=[\n",
    "        StructField(\"customer_id\", StringType()),\n",
    "        StructField(\"customer_name\", StringType()),\n",
    "        StructField(\"date_of_birth\", DateType()),\n",
    "        StructField(\"telephone\", StringType()),\n",
    "        StructField(\"email\", StringType()),\n",
    "        StructField(\"member_since\", DateType()),\n",
    "        StructField(\"created_timestamp\", TimestampType()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "customers_df = (\n",
    "    spark.readStream.format(\"json\")\n",
    "    .schema(customers_schema)\n",
    "    .load(\"/Volumes/gizmobox/landing/operational_data/customers_stream\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4900eb4-1b54-4a3d-9382-d16e78a4f3cd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "2. Transform the dataframe to add the following columns"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, current_timestamp\n",
    "\n",
    "customers_transformed_df = customers_df.withColumn(\n",
    "    \"file_path\", col(\"_metadata.file_path\")\n",
    ").withColumn(\"ingestion_timestamp\", current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91d523a7-1289-41f7-a812-8de220686227",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "3. Write the transformed data stream to Delta Lake Table"
    }
   },
   "outputs": [],
   "source": [
    "streaming_query = (\n",
    "    customers_transformed_df.writeStream.format(\"delta\")\n",
    "    .option(\n",
    "        \"checkpointLocation\",\n",
    "        \"/Volumes/gizmobox/landing/operational_data/customers_stream/_checkpoint_stream\",\n",
    "    )\n",
    "    .toTable(\"gizmobox.bronze.customers_stream\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbdba968-9cb6-46a6-bcd6-95cdc860a666",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "streaming_query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a45cd789-4b94-4d1e-afe5-3f0536787622",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  gizmobox.bronze.customers_stream;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7638583592061597,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "1. Ingest Customers Stream",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
